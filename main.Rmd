---
title: "R Notebook"
output: html_notebook
---

```{r fonts}
font_import(paths = "./fonts")
windowsFonts(sans="Roboto")
loadfonts(device="win")
loadfonts(device="postscript")
```


```{r library}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(tidytext)
library(stringr)
library('tm')
library(ggwordcloud)
library(topicmodels)
library(extrafont)
```

```{r tidy}
# importo i dataset originali
# Pulizia dei dataset
# rimozione delle righe in cui l'anno Ã¨ 'Not Defined'
# unione delle tabelle 'album_details' e 'lyrics'
# aggiungo campo DECADE che mi facilita l'analisi
# salvataggio dataset ripulito

album_details = read.csv("./data/album_details.csv")
lyrics = read.csv("./data/lyrics.csv")

album_details = album_details %>% arrange(singer_name) %>% filter(year >= 1950) %>% select(-type, -name, -id, -X)
album_details = album_details[album_details$year != "Not Defined", ]

lyrics = lyrics %>% arrange(artist) %>% select(-link, -song_name, -X)

clean_dataset = inner_join(album_details, lyrics, by = c("singer_name" = "artist"))

clean_dataset = clean_dataset %>% 
  mutate(decade =
    case_when(
      2010 <= year ~ "2010-2020",
      2000 <= year ~ "2000-2010",
      1990 <= year ~ "1990-2000",
      1980 <= year ~ "1980-1990",
      1970 <= year ~ "1970-1980",
      1960 <= year ~ "1960-1970",
      year < 1960 ~ "1950-1960"
    )
  ) %>% select(-year, decade, everything()) %>% arrange(decade)


write.csv(clean_dataset, file = "./data/lyrics_clean_dataset.csv")

clean_dataset %>% 
  select(song_name, decade) %>% 
  group_by(decade) %>% 
  summarize(n = n()) %>% 
  select(decade, n)
```


```{r tokenization}
# lyrics vanno dal 1950 al 2020, possiamo individuare 7 decadi
# - ottengo i token (unigrammi) per ogni decade corrispondente
#     + bigrammi, forse
# - salvataggio del dataset contenente i token
clean_dataset = read.csv("./data/lyrics_clean_dataset.csv")

# -- tokenization in UNIGRAMMI (decade, word, n)
unigrams_decade <- clean_dataset %>%
  select(lyrics, decade) %>%
  group_by(decade) %>% 
  unnest_tokens(word, lyrics) %>% 
  count(word, sort = TRUE)


# stop words SMART lexicon:
unigrams_decade <- unigrams_decade %>%
  anti_join(stop_words) %>% 
  arrange(decade, desc(n))

unigrams_decade$word = removePunctuation(unigrams_decade$word)
unigrams_decade$word = removeNumbers(unigrams_decade$word)
write.csv(unigrams_decade, file = "./data/unigrams_decade.csv")
```

```{r merge-with-english-dict}
# voglio mantenere tutti i token che hanno una corrispondenza nel vocabolario inglese (merged.csv)
# trim sul file per eliminare gli spazi (necessario: creavano problemi)
word_list = read.csv("./data/merged.csv")
word_list$word = str_trim(word_list$word)

unigrams_decade = read.csv("./data/unigrams_decade.csv")
unigrams_decade = unigrams_decade %>% filter(word %in% word_list$word)
write.csv(unigrams_decade, file = "./data/unigrams_decade.csv")
```

```{r lexicons}
# sentiment analysis per decade, utilizzando bing, afinn, nrc:
unigrams_decade_bing <- unigrams_decade %>%
  inner_join(get_sentiments("bing"))

unigrams_decade_afinn <- unigrams_decade %>%
  inner_join(get_sentiments("afinn"))

unigrams_decade_nrc <- unigrams_decade %>%
  inner_join(get_sentiments("nrc"))

# salvataggio files
write.csv(unigrams_decade_bing, file = "./data/BING_unigrams_decade.csv")
write.csv(unigrams_decade_afinn, file = "./data/AFINN_unigrams_decade.csv")
write.csv(unigrams_decade_nrc, file = "./data/NRC_unigrams_decade.csv")

unigrams_decade_bing
unigrams_decade_afinn
unigrams_decade_nrc
```

```{r sentiment-during-decade}
unigrams_decade_bing = read.csv("./data/BING_unigrams_decade.csv")

# Analiziamo la percentuale di parole positive/negative per ogni decade basandoci su bing lexicon:
bing_freq = unigrams_decade_bing %>% 
  group_by(decade, sentiment) %>% 
  summarise(n = sum(n)) %>% 
  spread(key = sentiment, value = n) %>% 
  mutate(total = sum(negative)+sum(positive)) %>% 
  mutate("negative" = round(negative/total, digits = 3), 
         "positive" = round(positive/total, digits = 3)) %>% 
  select(-total) %>% 
  arrange(negative)

# utilizziamo i dati precedentemente raccolti (bing_freq)  
# plottare la percenutuale di sentiment negativo e positivo per ogni decade 
graph = bing_freq %>% 
  pivot_longer(c('positive', 'negative'), names_to = "sentiment", values_to = "freq") %>% 
  ggplot(aes(x = decade, y = freq, fill = sentiment)) +
  geom_bar(position = "stack", stat = "identity") + 
  scale_fill_manual("sentiment", values = c("positive" = "#009688", "negative" = "#212121")) +
  labs(title = NULL,subtitle = NULL, y = NULL,x = NULL) + theme_minimal() +
  theme(text=element_text(family="Roboto Thin", size=10))

print(graph)
ggsave(graph, filename = "./graphs/BING_lex_decade.png", device = "png")
```

```{r wordclouds}
unigrams_decade_nrc = read.csv("./data/NRC_unigrams_decade.csv")
wc_geom_text = geom_text_wordcloud(eccentricity = 1, rm_outside = TRUE)
wc_scale_size = scale_size_area(max_size = 50)
wc_scale_color = scale_color_manual(values = c("#212121", "#009688"))
set.seed(42)

unigrams_decade_bing %>% 
  filter(decade == "1950-1960") %>% 
  select(word, n, sentiment) %>% 
  arrange(desc(n)) %>% head(50) %>% 
  ggplot(aes(label = word, size = n, color = sentiment)) +
  wc_geom_text + wc_scale_size + wc_scale_color + theme_minimal()
unigrams_decade_bing %>% 
  filter(decade == "1960-1970") %>% 
  select(word, n, sentiment) %>% 
  arrange(desc(n)) %>% head(50) %>% 
  ggplot(aes(label = word, size = n, color = sentiment)) +
  wc_geom_text + wc_scale_size + wc_scale_color + theme_minimal()
unigrams_decade_bing %>% 
  filter(decade == "1970-1980") %>% 
  select(word, n, sentiment) %>% 
  arrange(desc(n)) %>% head(50) %>% 
  ggplot(aes(label = word, size = n, color = sentiment)) +
  wc_geom_text + wc_scale_size + wc_scale_color + theme_minimal()
unigrams_decade_bing %>% 
  filter(decade == "1980-1990") %>% 
  select(word, n, sentiment) %>% 
  arrange(desc(n)) %>% head(50) %>% 
  ggplot(aes(label = word, size = n, color = sentiment)) +
  wc_geom_text + wc_scale_size + wc_scale_color + theme_minimal()
unigrams_decade_bing %>% 
  filter(decade == "1990-2000") %>% 
  select(word, n, sentiment) %>% 
  arrange(desc(n)) %>% head(50) %>% 
  ggplot(aes(label = word, size = n, color = sentiment)) +
  wc_geom_text + wc_scale_size + wc_scale_color + theme_minimal()
unigrams_decade_bing %>% 
  filter(decade == "2000-2010") %>% 
  select(word, n, sentiment) %>% 
  arrange(desc(n)) %>% head(50) %>% 
  ggplot(aes(label = word, size = n, color = sentiment)) +
  wc_geom_text + wc_scale_size + wc_scale_color + theme_minimal()
unigrams_decade_bing %>% 
  filter(decade == "2010-2020") %>% 
  select(word, n, sentiment) %>% 
  arrange(desc(n)) %>% head(50) %>% 
  ggplot(aes(label = word, size = n, color = sentiment)) +
  wc_geom_text + wc_scale_size + wc_scale_color + theme_minimal()
```

```{r sentiment-trends}
# utilizziamo NRC per plottare le tipologie di sentiment nel tempo
unigrams_decade_nrc %>% 
  group_by(decade, sentiment) %>% 
  summarise(freq = sum(n)/total) %>% 
  select(decade, sentiment, freq) %>% 
  filter(sentiment %in% c("anger", "fear", "disgust", "joy", "trust", "anticipation")) %>% 
  ggplot( aes(x=decade, y=freq, group=sentiment, color=sentiment)) +
    geom_line(size = 1, linetype = 2) + geom_point()+ theme_minimal() + 
  theme(legend.position="bottom") + 
  labs(x = element_blank(), 
       y = element_blank())
```


```{r document-term-freq, fig.width=10, fig.height=2.5 }
# Word and Document Term Frequency
unigrams_decade = read.csv("./data/unigrams_decade.csv")

total_words <- unigrams_decade %>% 
  group_by(decade) %>% 
  summarize(total = sum(n))
freq_hist = geom_histogram(show.legend = FALSE, bins = 15, fill = "#009688")
unigrams_decade <- left_join(unigrams_decade, total_words)

unigrams_decade %>% 
  filter(decade %in% c("1950-1960", "1960-1970", "1970-1980", "1980-1990")) %>% 
  ggplot(aes(n/total, fill = decade)) +
    geom_histogram(show.legend = FALSE, bins = 30) +
    xlim(NA, 0.0005) +
    facet_wrap(~decade, ncol = 4, scales = "free_y") + 
    theme(axis.text.x=element_blank()) + labs(x = element_blank(), y = element_blank()) +
    scale_fill_manual(values=c("#18568F","#18568F", "#18568F", "#18568F"))


unigrams_decade %>% 
  filter(decade %in% c("1990-2000", "2000-2010", "2010-2020")) %>% 
  ggplot(aes(n/total, fill = decade)) +
    geom_histogram(show.legend = FALSE, bins = 30) +
    xlim(NA, 0.0002) +
    facet_wrap(~decade, ncol = 3, scales = "free_y") + 
    theme(axis.text.x=element_blank()) + labs(x = element_blank(), y = element_blank()) +
    scale_fill_manual(values=c("#18568F","#18568F", "#18568F"))

```

```{r zipfs-law}
# ZIPFS LAW
unigrams_decade = read.csv("./data/unigrams_decade.csv")

freq_by_rank <- unigrams_decade %>% 
  group_by(decade) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total) %>%
  ungroup()

freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = decade)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) + 
  geom_abline(intercept = -0.62, slope = -1.1, color = "black", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() + scale_y_log10()  +
  theme (
    plot.title = element_text(face = "bold", size = (17)),
    axis.text.x = element_text(size=9, angle=35),
    plot.caption= element_text(size=5, vjust = 10)
  ) + 
  labs(y = "Term Frequency",x = "Rank") + theme_minimal()
```


```{r top-five-occurences, fig.width=9, fig.height=7}
# Top 5 parole più usate
unigrams_decade %>%
  group_by(decade) %>%
  arrange(desc(n)) %>% 
  slice_max(n, n = 5) %>% 
  ggplot(aes(n/total, fct_reorder(word, n), fill = decade)) +
  geom_col(show.legend = TRUE) + theme_get() +
  facet_wrap(~decade, ncol = 2, scales = "free_y") +
  labs(x = element_blank(), y = element_blank()) + 
  scale_fill_manual(values=c("#009688","#00C9B1", "#8E78CC", "#BB7539", "#5987C5", "#AE71A5", "#344B47"))
```


```{r tf-idf, fig.width=8, fig.height=3}
# tf-idf (DOCUMENTI = decadi)
unigrams_decade = read.csv("./data/unigrams_decade.csv")

unigrams_total_words <- unigrams_decade %>% 
  group_by(decade) %>% 
  summarize(total = sum(n))

unigrams_decade <- left_join(unigrams_decade, unigrams_total_words)

unigrams_decade_tf_idf = unigrams_decade %>%
  bind_tf_idf(word, decade, n)

tf_labs = labs(x = element_blank(), y = element_blank())


#Faccio due grafici separati (questioni stilistiche)
# tf-idf dal '50 al '80
unigrams_decade_tf_idf %>%
  filter(decade %in% c("1950-1960", "1960-1970", "1970-1980")) %>% 
  group_by(decade) %>%
  slice_max(tf_idf, n = 7) %>%
  ungroup() %>%
  ggplot(aes(x = tf_idf, y = fct_reorder(word, tf_idf), fill = decade)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~decade, ncol = 3, scales = "free_y") +
  theme (
    plot.title = element_text(size = (15)),
    axis.text.x = element_text(size=7, face = "italic"),
    axis.text.y = element_text(size=8, face = "bold"),
  ) + tf_labs

# tf-idf dal '80 al '020
unigrams_decade_tf_idf %>%
  filter(decade %in% c("1980-1990", "1990-2000", "2000-2010", "2010-2020")) %>% 
  group_by(decade) %>%
  slice_max(tf_idf, n = 7) %>%
  ungroup() %>%
  ggplot(aes(x = tf_idf, y = fct_reorder(word, tf_idf), fill = decade)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~decade, ncol = 4, scales = "free_y") +
  theme (
    plot.title = element_text(size = (15)),
    axis.text.x = element_text(size=7, face = "italic"),
    axis.text.y = element_text(size=8, face = "bold"),
  ) + tf_labs + 
  scale_fill_manual(values=c("#BB7539", "#5987C5", "#AE71A5", "#344B47"))
```


```{r topic-modelling}
labs = labs(x = NULL, y = "Log2 ratio of beta in topics 2/1")
scale = scale_fill_manual(values=c("#BB7539", "#5987C5", "#AE71A5", "#344B47"))

uni50_60 = unigrams_decade %>% 
  filter(decade == "1950-1960") %>% 
  select(word, n, decade) %>% 
  as_tibble() %>% 
  cast_dtm(decade, word, n) %>% 
  LDA(k = 2, control = list(seed = 1234)) %>% 
  tidy(matrix = "beta") %>% 
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>% 
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio, fill = direction)) +
  geom_col(show.legend = FALSE) +
  labs + coord_flip() + theme_minimal() + scale

uni60_70 = unigrams_decade %>% 
  filter(decade == "1960-1970") %>% 
  select(word, n, decade) %>% 
  as_tibble() %>% 
  cast_dtm(decade, word, n) %>% 
  LDA(k = 2, control = list(seed = 1234)) %>% 
  tidy(matrix = "beta") %>% 
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>% 
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio, fill = direction)) +
  geom_col(show.legend = FALSE) +
  labs + coord_flip() + theme_minimal() + scale


uni70_80 = unigrams_decade %>% 
  filter(decade == "1970-1980") %>% 
  select(word, n, decade) %>% 
  as_tibble() %>% 
  cast_dtm(decade, word, n) %>% 
  LDA(k = 2, control = list(seed = 1234)) %>% 
  tidy(matrix = "beta") %>% 
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>% 
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio, fill = direction)) +
  geom_col(show.legend = FALSE) +
  labs + coord_flip() + theme_minimal() + scale


uni80_90 = unigrams_decade %>% 
  filter(decade == "1980-1990") %>% 
  select(word, n, decade) %>% 
  as_tibble() %>% 
  cast_dtm(decade, word, n) %>% 
  LDA(k = 2, control = list(seed = 1234)) %>% 
  tidy(matrix = "beta") %>% 
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>% 
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio, fill = direction)) +
  geom_col(show.legend = FALSE) +
  labs + coord_flip() + theme_minimal() + scale


uni90_00 = unigrams_decade %>% 
  filter(decade == "1990-2000") %>% 
  select(word, n, decade) %>% 
  as_tibble() %>% 
  cast_dtm(decade, word, n) %>% 
  LDA(k = 2, control = list(seed = 1234)) %>% 
  tidy(matrix = "beta") %>% 
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>% 
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio, fill = direction)) +
  geom_col(show.legend = FALSE) +
  labs + coord_flip() + theme_minimal() + scale

uni00_10 = unigrams_decade %>% 
  filter(decade == "2000-2010") %>% 
  select(word, n, decade) %>% 
  as_tibble() %>% 
  cast_dtm(decade, word, n) %>% 
  LDA(k = 2, control = list(seed = 1234)) %>% 
  tidy(matrix = "beta") %>% 
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>% 
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio, fill = direction)) +
  geom_col(show.legend = FALSE) +
  labs + coord_flip() + theme_minimal() + scale


uni10_20 = unigrams_decade %>% 
  filter(decade == "2010-2020") %>% 
  select(word, n, decade) %>% 
  as_tibble() %>% 
  cast_dtm(decade, word, n) %>% 
  LDA(k = 2, control = list(seed = 1234)) %>% 
  tidy(matrix = "beta") %>% 
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>% 
  group_by(direction = log_ratio > 0) %>%
  top_n(10, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(term = reorder(term, log_ratio)) %>%
  ggplot(aes(term, log_ratio, fill = direction)) +
  geom_col(show.legend = FALSE) +
  labs + coord_flip() + theme_minimal() + scale

uni50_60
uni60_70
uni70_80
uni80_90
uni90_00
uni00_10
uni10_20

# solo alcune decadi presentano risultati significativi
```

